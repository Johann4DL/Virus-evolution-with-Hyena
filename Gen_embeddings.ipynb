{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from utils import count_parameters, read\n",
    "from config import hyena_config\n",
    "from hyena_simp import Config, HyenaConfig, AuthenticHyenaBlock, FastaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastaModel(\n",
       "  (tok_emb): Embedding(13, 10)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): AuthenticHyenaBlock(\n",
       "      (proj_input): Projection(\n",
       "        (linear): Linear(in_features=10, out_features=30, bias=True)\n",
       "        (conv): Conv1d(30, 30, kernel_size=(3,), stride=(1,), padding=(2,), groups=30)\n",
       "      )\n",
       "      (proj_output): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (filter): AuthenticHyenaFilter(\n",
       "        (pos_emb): PositionalEmbedding()\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "          (1): Sin()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sin()\n",
       "          (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (5): Sin()\n",
       "          (6): Linear(in_features=64, out_features=20, bias=False)\n",
       "        )\n",
       "        (window): AuthenticWindow()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (fft_conv): FFTConv()\n",
       "    )\n",
       "    (1): AuthenticHyenaBlock(\n",
       "      (proj_input): Projection(\n",
       "        (linear): Linear(in_features=10, out_features=30, bias=True)\n",
       "        (conv): Conv1d(30, 30, kernel_size=(3,), stride=(1,), padding=(2,), groups=30)\n",
       "      )\n",
       "      (proj_output): Linear(in_features=10, out_features=10, bias=True)\n",
       "      (filter): AuthenticHyenaFilter(\n",
       "        (pos_emb): PositionalEmbedding()\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=5, out_features=64, bias=True)\n",
       "          (1): Sin()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sin()\n",
       "          (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (5): Sin()\n",
       "          (6): Linear(in_features=64, out_features=20, bias=False)\n",
       "        )\n",
       "        (window): AuthenticWindow()\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (fft_conv): FFTConv()\n",
       "    )\n",
       "  )\n",
       "  (down): Linear(in_features=30000, out_features=1000, bias=False)\n",
       "  (up): Linear(in_features=1000, out_features=30000, bias=False)\n",
       "  (lnorm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=10, out_features=13, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FastaModel(hyena_config, AuthenticHyenaBlock)\n",
    "model.load_state_dict(torch.load('models/model_state_dict.pt'))\n",
    "model.eval()\n",
    "\n",
    "# model_2 = FastaModel(hyena_config, AuthenticHyenaBlock)\n",
    "# model_2.load_state_dict(torch.load('models/model_state_dict.pt'))\n",
    "# model_2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add weights of two state_dicts\n",
    "# for name, param in model.named_parameters():\n",
    "#     if name in model_2.state_dict():\n",
    "#         param.data = model_2.state_dict()[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genome sequences:  2250\n",
      "Min and max length of genome sequences after padding:\n",
      "Min:  30000 \n",
      "Max:  30000\n"
     ]
    }
   ],
   "source": [
    "path = './data/all_genomes.fasta'\n",
    "\n",
    "data = read(path)\n",
    "# selsct the first 2250 sequences\n",
    "data = data[:2250]\n",
    "print('Number of genome sequences: ',len(data))\n",
    "\n",
    "# preprocessing\n",
    "CONTEXT_LENGTH = 30000\n",
    "\n",
    "# cut sequences to CONTEXT_LENGTH\n",
    "for i in range(len(data)):\n",
    "    if len(data[i]) >= CONTEXT_LENGTH:\n",
    "        data[i] = data[i][:CONTEXT_LENGTH]\n",
    "# apply 'P' padding to the sequences\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i] + 'P' * (CONTEXT_LENGTH - len(data[i]))\n",
    "\n",
    "min_length = min([len(x) for x in data])\n",
    "max_length = max([len(x) for x in data])\n",
    "\n",
    "print('Min and max length of genome sequences after padding:\\nMin: ', min_length,'\\nMax: ', max_length)\n",
    "\n",
    "# Tokenize\n",
    "\n",
    "chars = set()\n",
    "\n",
    "for genome in data:\n",
    "    for char in genome:\n",
    "        chars.add(char)\n",
    "vocabulary = list(chars)\n",
    "\n",
    "\n",
    "tok2id = {ch: i for i, ch in enumerate(vocabulary)}\n",
    "id2tok = {i: ch for i, ch in enumerate(vocabulary)}\n",
    "\n",
    "encode = lambda s: [tok2id[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([id2tok[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings_DS(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = np.random.randint(len(self.data))\n",
    "        data = self.data[idx]\n",
    "        data = torch.tensor(encode(data))\n",
    "\n",
    "        return data\n",
    "\n",
    "# Datasets\n",
    "\n",
    "# train_ds = Embeddings_DS(train_data)\n",
    "val_ds = Embeddings_DS(val_data)\n",
    "\n",
    "# Dataloader\n",
    "# loader = DataLoader(train_ds, batch_size=hyena_config.batch_size, shuffle=True, num_workers=10)\n",
    "val_loader = DataLoader(val_ds, batch_size=hyena_config.batch_size, shuffle=True, num_workers=10)\n",
    "\n",
    "model = FastaModel(hyena_config, AuthenticHyenaBlock)\n",
    "m = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 5.948329902225071\n"
     ]
    }
   ],
   "source": [
    "val_loss_ = []\n",
    "model.eval()\n",
    "embeddings = []\n",
    "for batch in val_loader:\n",
    "    batch = batch.to('cuda')\n",
    "    logits, genome_embedding = model(batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.transpose(1, 2), batch\n",
    "    )\n",
    "    val_loss_.append(loss.item())\n",
    "    embeddings.append(genome_embedding.detach().cpu().numpy())\n",
    "\n",
    "# accumulate val loss\n",
    "tot_val_loss = sum(val_loss_) / len(val_loss_) \n",
    "print(f'Validation loss: {tot_val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings (10, 1000)\n",
      "[[-1.04405728e+08 -2.75099040e+07 -6.44010200e+07 ... -4.77720320e+07\n",
      "  -4.02863480e+07 -1.53021344e+08]\n",
      " [-2.93668640e+07 -4.15380480e+07 -4.62524200e+07 ... -1.01571030e+07\n",
      "  -7.29748800e+07 -9.51161360e+07]\n",
      " [-5.72926480e+07  5.68492800e+07  1.58430000e+08 ... -7.48765600e+07\n",
      "  -1.17196960e+08 -8.06539840e+07]\n",
      " ...\n",
      " [-7.05785760e+07  1.13798616e+08  1.16629528e+08 ... -1.91570752e+08\n",
      "  -1.89325888e+08 -1.18564888e+08]\n",
      " [ 8.38409920e+07 -1.32136528e+08 -4.35611520e+07 ...  1.66617376e+08\n",
      "   1.91753056e+08  1.34499360e+08]\n",
      " [-3.86077280e+07  1.57334304e+08 -1.52868600e+07 ... -1.56067104e+08\n",
      "  -2.83712000e+07 -6.36987680e+07]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embeddings)):\n",
    "    embeddings[i] = embeddings[i].squeeze(0)\n",
    "\n",
    "print('Shape of embeddings', embeddings[0].shape)\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "embeddings = torch.cat(embeddings, dim=0)\n",
    "print('Shape of embeddings', embeddings.shape)\n",
    "embeddings = embeddings.cpu().detach().numpy()\n",
    "print('Shape of embeddings', embeddings.shape)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(embeddings)\n",
    "print('Centroids: ', kmeans.cluster_centers_)\n",
    "print('Labels: ', kmeans.labels_)\n",
    "print('Inertia: ', kmeans.inertia_)\n",
    "print('Number of iterations: ', kmeans.n_iter_)\n",
    "print('Predictions: ', kmeans.predict(embeddings))\n",
    "\n",
    "# t-SNE visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=kmeans.labels_)\n",
    "plt.title('t-SNE visualization of genome embeddings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggregate genomic data in one file -> split in parts of 2500 -> train separate models on each data chunk.\n",
    "\n",
    "validation data: either a fraction of each chunk or the aggragated validation data of all data chunks.\n",
    "\n",
    "aggregate model weights -> only add weights, if it improves over all validation accuracy.\n",
    "\n",
    "Kmenas clustering and write someting in overleaf.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate new genomes, based on previous period -> generate embeddings for them -> cluster embeddings -> compare new embeddings and groubnd truth cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
